why am I implementing FBA analysis model into my dataset?
Because I need to have a better theoretical understanding.

Balances (conserved quantities) -> energy, mass, momentum, osmotic pressure, solvent capacity, electro-neutrality

Bounds (limit numerical ranges of variables) -> concentrations, fluxes, kinetic constants

constraints on the level of - diversity on production plans
							- resources
							intrinsic capabilities (how many links do we have in the network? Non-zero elements do we have in stochiometric matrix?)

19.03.21
An organism metabolic model of Homo Sapiens (738 metabolites, 1008 reactions) was downloaded from BIGG Models Database. Since its stoichiometric matrix density is quite small (0.00539), I have kept the size of the rows (738) but reduced the size of the columns from 1008 to 20 by randomly choosing non-zero elements from each row. My finalized stoic. matrix size is 738 x 20 (nodes/metabolites x features/flux exchanges).
Randomly created 10 objective functions are considered. Their coefficients vary from -2 to 2 and I kept the zero elements: non-zero elements ratio as 2:1 in objective functions.
I have assigned random boundaries for features.
With above-mentioned items, my solution vectors result in zero vectors. I am doing some minor adjustments however still could not obtain vectors with values yet.

20.03.21

I have used the complete stoichiometric matrix of Homo Sapiens organism metabolic model. After I had the solution vector results, defined the zero columns of solution vectors and erased them from the stoic. matrix and restarted the linear programming. In two steps, I have obtained a narrower solution vector (with less flux exchanges/features).

04.05.21

•	Plots in Part-1 of the file belong to association networks of four different synthetically created sequence data sets, and each represented in various colors: green, blue, orange, and red. Part-1 data sets were derived with fixed reaction bounds but with varying coefficients of objective functions. Part-2 also presents plots for four different synthetically created sequence data sets with fixed objective function coefficients but with variable reaction bounds.
•	Each data set has a length of 60,000 events shared equally in 200 sequences. Randomly picked subsets of fluxes were kept the same within the sequences but having varying coefficients of objective functions.
•	The association network data sets were structured by the dot products of objective function vectors and optimized solution vectors. This product results maximize the output, if I am not wrong, as the maximization attempt of biomass in the FBA model.
•	The below graph represents the reaction-centric network computed from the Homo Sapiens metabolic model's stoichiometric matrix, which is currently used for synthetic data generation. The nodes arbitrarily highlighted in different colors represent the fluxes that belong to the same sequence.

20.05.21

The data sets synthetically created with OR-model were investigated by building their association networks in two alternative binning methods: a binning with equal bin sizes (Fixed Step Size: FSS) vs. a binning with equal event counts per bin (Fixed Bucket Size: FBS). Modularities of those networks were compared with the modularity values of two different null models: Fixed Degree Sequence Null Model and Modularity Null Model. Synthetic data modularity, single random graph modularity, and z-score changes were shown in y-axes of those three plots, while randomly deleting reactions were given in the x-axes. Each association network with randomly deleted reactions consists of 60,000 events generated by the OR model. Data sets with a length of 60,000 events shared equally in 200 sequences. Randomly picked subsets of reactions were kept the same within the sequences but having varying coefficients of objective functions. Before building the association network, the suitable data structure was obtained by the dot products of Objective Function Vectors and Optimized Solution Vectors. This maximized tensor output resulted from dot product consists of 60,000 events, namely the feature data column, which was considered to build the association network.  

The above-explained analysis pipeline was applied in two main parts with different initial conditions. In Part-1, synthetic data sets were derived with 105 pcs constrained reaction bounds in [-5,5] interval in the consideration of four sets of Objective Function Coefficients (OFC) assigned to reaction in ranges: (-4,-2), (-1,1), (2,4) and (-4,4). The four different OFC series were created randomly, including zero values. The randomly selected 105 reactions for bound restriction and assigned OFS sets were kept the same during the whole investigation. Part-2 synthetic data sets were generated using the two OFC sets created in Part-1 with the intervals: (-1,1) and (2,4) under five cases with differently constrained bound intervals. The same 105 reactions constrained in the bound interval [-5,5] from the Part-1 investigation were kept as the first case, and the following four cases were derived from it by updating the bound intervals as [-0.5,0.5], [-50,50] and reaction amount increased to 210.